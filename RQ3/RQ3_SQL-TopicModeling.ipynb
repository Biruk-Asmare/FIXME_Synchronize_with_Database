{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Import libraries</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim import corpora, models\n",
    "import pyLDAvis.gensim\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "from itertools import chain\n",
    "import string\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import math\n",
    "import pickle\n",
    "from nltk.stem.porter import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>SQL Dataset</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_df=pd.read_csv(\"../Data_Collection/SQL_raw_dataset.csv\")\n",
    "sql_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove duplicate comments from the dataset\n",
    "sdata=sql_df[sql_df[\"is_dac\"]==True] #select only data-access SATD\n",
    "sdata = sdata.sort_values('version', ascending=False)\n",
    "sdata.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata = sdata.drop_duplicates(subset=\"comment\", keep='first')\n",
    "sdata.info()\n",
    "sdata.to_csv(\"DAC_SQL_dataset_NoDuplicates.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Data Cleaning </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words= set(stopwords.words('english'))\n",
    "stop_words.add(\"todo\") #too common\n",
    "stop_words.add(\"fixme\") #too common\n",
    "remove= set(string.punctuation)\n",
    "stemmer= SnowballStemmer(language=\"english\")\n",
    "def lemmatize_and_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "def get_cleaned_list(text):\n",
    "    re_stop_word=' '.join([word for word in text.lower().split() if word not in stop_words])\n",
    "    re_punc=''.join(c for c in re_stop_word if c not in remove)\n",
    "    #stem_text=' '.join([stemmer.stem (token) for token in re_punc.split()])\n",
    "    lema_text=' '.join([lemmatize_and_stemming (token) for token in re_punc.split()])\n",
    "    return lema_text.split()\n",
    "    #return stem_text.split() #uncomment for LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata['clean_comments']= sdata.comment.apply(get_cleaned_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sdata.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>LDA with TF-IDF</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dictionary\n",
    "docs=sdata['clean_comments'].tolist()\n",
    "dictionary = gensim.corpora.Dictionary(docs)\n",
    "len(dictionary)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create BOW for each doc\n",
    "bow=[dictionary.doc2bow(doc) for doc in docs]\n",
    "len(bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create TF-IDF model\n",
    "tfidf = models.TfidfModel(bow)\n",
    "docs_tfidf=tfidf[bow]\n",
    "len(docs_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LDA\n",
    "lda_model = gensim.models.LdaMulticore(docs_tfidf, num_topics=75, passes=4, id2word=dictionary, workers=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets find optimum topics\n",
    "for topic in range(5,75,5):\n",
    "\n",
    "    lda_model = gensim.models.LdaMulticore(docs_tfidf, num_topics=topic, passes=1,random_state=100, id2word=dictionary, workers=6)\n",
    "    coherence_model= CoherenceModel(model=lda_model, texts=docs, dictionary=dictionary, coherence='c_v')\n",
    "    coherence= coherence_model.get_coherence()\n",
    "    print(\"{},{} \\n\".format(topic,coherence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets find optimum passes\n",
    "for _pass in range(1,20):\n",
    "    lda_model = gensim.models.LdaMulticore(docs_tfidf, num_topics=50, passes=_pass,random_state=100, id2word=dictionary, workers=6)\n",
    "    coherence_model= CoherenceModel(model=lda_model, texts=docs, dictionary=dictionary, coherence='c_v')\n",
    "    coherence= coherence_model.get_coherence()\n",
    "    print(\"{},{} \\n\".format(_pass,coherence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets find optimum beta\n",
    "betas = list(np.arange(0.01, 1, 0.3))\n",
    "betas.append('symmetric')\n",
    "for beta in betas:\n",
    "    lda_model = gensim.models.LdaMulticore(docs_tfidf, num_topics=50, passes=1,eta=beta,random_state=100, id2word=dictionary, workers=6)\n",
    "    coherence_model= CoherenceModel(model=lda_model, texts=docs, dictionary=dictionary, coherence='c_v')\n",
    "    coherence= coherence_model.get_coherence()\n",
    "    print(\"{},{} \\n\".format(beta,coherence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets find optimum alpha passes=1\n",
    "alphas = list(np.arange(0.01, 1, 0.3))\n",
    "alphas.append('symmetric')\n",
    "alphas.append('asymmetric')\n",
    "for alpha in alphas:\n",
    "    lda_model = gensim.models.LdaMulticore(docs_tfidf, num_topics=50, passes=1,alpha=alpha,random_state=100, id2word=dictionary, workers=6)\n",
    "    coherence_model= CoherenceModel(model=lda_model, texts=docs, dictionary=dictionary, coherence='c_v')\n",
    "    coherence= coherence_model.get_coherence()\n",
    "    print(\"{},{} \\n\".format(alpha,coherence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final model\n",
    "lda_model = gensim.models.LdaMulticore(docs_tfidf, num_topics=20, passes=1,random_state=100, id2word=dictionary, workers=6)\n",
    "coherence_model= CoherenceModel(model=lda_model, texts=docs, dictionary=dictionary, coherence='c_v')\n",
    "coherence= coherence_model.get_coherence()\n",
    "print(\"Coherence score: {} \".format(coherence))\n",
    "#save the model as pkl\n",
    "lda_model.save(\"SqlTopicModel.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now classsify the comments, based on the topic\n",
    "results=[]\n",
    "\n",
    "for b in bow:\n",
    "    res=lda_model.get_document_topics(b, minimum_probability=0)\n",
    "    #print(\"{:.60f}\".format(row[1]))\n",
    "    topic=max(res, key=lambda x: x[1])\n",
    "    print(topic)\n",
    "    results.append(topic[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata[\"topic\"]=results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata.groupby(['topic']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata[sdata[\"topic\"]==9].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the classified data as csv\n",
    "sdata.to_csv(\"DAC_SQL_dataset_final_NoDuplicates_Classified.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge sql and nosql data frames\n",
    "nsdata=pd.read_csv(\"DAC_NOSQL_dataset_final_NoDuplicates_Classified.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsdata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined= pd.concat([sdata,nsdata],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined= combined.drop(columns=[\"type\",\"is_dac\",\"clean_comments\"])\n",
    "combined.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.to_csv(\"DAC_combined_dataset_final_NoDuplicates_Classified.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
